{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/ocean/projects/cis240129p/soederha/silent_speech\")\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from lib_alice import BrennanDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "base_dir = Path(\"/ocean/projects/cis240129p/shared/data/eeg_alice\")\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()  \n",
    "\n",
    "subjects_used = [\"S01\", \"S03\", \"S04\", \"S08\", \"S11\", \"S12\", \"S13\", \"S16\", \"S17\", \"S18\", \"S19\", \"S22\", \"S26\", \"S36\", \"S37\", \"S40\", \"S41\", \"S42\", \"S44\", \"S48\"]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(subjects, base_dir, augmented_eeg_dict = None):\n",
    "    train_datasets = []\n",
    "    test_datasets = []\n",
    "    for subject in subjects:\n",
    "        dataset = BrennanDataset(\n",
    "            root_dir=base_dir,\n",
    "            phoneme_dir=base_dir / \"phonemes\",\n",
    "            idx=subject,\n",
    "            phoneme_dict_path=base_dir / \"phoneme_dict.txt\",\n",
    "            augmented_eeg_dict=augmented_eeg_dict,\n",
    "        )\n",
    "        num_data_points = len(dataset)\n",
    "\n",
    "        # Split indices into train and test sets\n",
    "        split_index = int(num_data_points * 1)\n",
    "        train_indices = list(range(split_index))\n",
    "        #test_indices = list(range(split_index, num_data_points))\n",
    "\n",
    "        # Create Subset datasets using indices\n",
    "        train_dataset = Subset(dataset, train_indices)\n",
    "        #test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "        train_datasets.append(train_dataset)\n",
    "        #test_datasets.append(test_dataset)\n",
    "    return train_datasets#, test_datasets\n",
    "\n",
    "\n",
    "#train_ds, test_ds = create_datasets(subjects_used, base_dir)\n",
    "train_ds = create_datasets(subjects_used, base_dir)\n",
    "train_dataset = ConcatDataset(train_ds)\n",
    "#test_dataset = ConcatDataset(test_ds)\n",
    "'''print(\n",
    "    f\"Train dataset length: {len(train_dataset)}, Test dataset length: {len(test_dataset)}\"\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot eeg raw vs eeg feat\n",
    "\n",
    "eeg_raw = train_dataset[2][\"eeg_raw\"]\n",
    "eeg_feat = train_dataset[2][\"eeg_feats\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylim(-3, 3)\n",
    "plt.plot(eeg_raw)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(eeg_feat)\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(eeg_feat)\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(eeg_raw.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    A custom collate function that handles different types of data in a batch.\n",
    "    It dynamically creates batches by converting arrays or lists to tensors and\n",
    "    applies padding to variable-length sequences.\n",
    "    \"\"\"\n",
    "    batch_dict = {}\n",
    "    for key in batch[0].keys():\n",
    "        batch_items = [item[key] for item in batch]\n",
    "        if isinstance(batch_items[0], np.ndarray) or isinstance(\n",
    "            batch_items[0], torch.Tensor\n",
    "        ):\n",
    "            if isinstance(batch_items[0], np.ndarray):\n",
    "                batch_items = [torch.tensor(b) for b in batch_items]\n",
    "            if len(batch_items[0].shape) > 0:\n",
    "                batch_dict[key] = torch.nn.utils.rnn.pad_sequence(\n",
    "                    batch_items, batch_first=True  # pad with zeros\n",
    "                )\n",
    "            else:\n",
    "                batch_dict[key] = torch.stack(batch_items)\n",
    "        else:\n",
    "            batch_dict[key] = batch_items\n",
    "\n",
    "    return batch_dict\n",
    "\n",
    "\n",
    "train_dataloder = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for batch in train_dataloder:\n",
    "    print(type(batch))\n",
    "    print(batch.keys())\n",
    "    print(batch['eeg_raw'].shape)\n",
    "    #print(batch['label'])\n",
    "    #print(batch['eeg_feats'].shape)\n",
    "    \n",
    "    print(batch['label'])\n",
    "    i+=1\n",
    "    if i>1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGAutoencoder(nn.Module):\n",
    "    def __init__(self, sequence_lenth=520, feature_dim=60,latent_dim=256):\n",
    "        super(EEGAutoencoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = sequence_lenth * feature_dim\n",
    "        self.sequence_length = sequence_lenth\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.input_dim),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.encoder(x) \n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_var(x)\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.decoder(z)\n",
    "        return x.view(-1, self.sequence_length, self.feature_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decode(z), mu, log_var\n",
    "\n",
    "def train_eeg_vae(model, train_loader, optimizer, device, epoch, data_type='eeg_raw'):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kld_loss = 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_recon_loss = 0.0\n",
    "    running_kld_loss = 0.0\n",
    "    \n",
    "    batch_pbar = tqdm(train_dataloder, desc=f'Epoch {epoch}', leave=False)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(batch_pbar):\n",
    "        eeg_feats = batch[data_type].float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = model(eeg_feats)\n",
    "    \n",
    "        reconstruction_loss = F.mse_loss(recon_batch, eeg_feats, reduction='mean')/eeg_feats.size(0)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())/eeg_feats.size(0)\n",
    "        \n",
    "        beta = 0.1 \n",
    "        loss = reconstruction_loss + beta * kld_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_recon_loss += reconstruction_loss.item()\n",
    "        total_kld_loss += kld_loss.item()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        current_loss = running_loss / (batch_idx + 1)\n",
    "        \n",
    "        running_recon_loss += reconstruction_loss.item()\n",
    "        current_recon_loss = running_recon_loss / (batch_idx + 1)\n",
    "        \n",
    "        running_kld_loss += kld_loss.item()\n",
    "        current_kld_loss = running_kld_loss / (batch_idx + 1)\n",
    "        \n",
    "        batch_pbar.set_postfix({\n",
    "                'loss': f'{current_loss:.4f}',\n",
    "                'recon': f'{current_recon_loss:.4f}',\n",
    "                'kld': f'{current_kld_loss:.4f}'\n",
    "            })\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torchsummaryX import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = EEGAutoencoder(sequence_lenth=520, feature_dim=60, latent_dim=64).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "test = torch.zeros(2, 520, 60).to(device) \n",
    "summary(model, test)\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_eeg_vae(model, train_dataloder, optimizer, device, epoch, data_type='eeg_raw')\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'====> Epoch: {epoch} Average loss: {train_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_by_word(model, train_dataloder, word_target):\n",
    "    \"\"\"\n",
    "    Get the mean latent vector for a specific word from the training data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    word_latents = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(train_dataloder):\n",
    "            labels = batch['label']\n",
    "            eeg_feats = batch['eeg_raw'].float().to(device)\n",
    "            \n",
    "            word_indices = [i for i, label in enumerate(labels) if label == word_target]\n",
    "            \n",
    "            if word_indices:\n",
    "                word_eeg = eeg_feats[word_indices]\n",
    "                \n",
    "                mu, _ = model.encode(word_eeg)\n",
    "                word_latents.append(mu)\n",
    "    if word_latents:\n",
    "        word_latents = torch.cat(word_latents, dim=0)\n",
    "        mean_latent = torch.mean(word_latents, dim=0)\n",
    "        var_latent = torch.var(word_latents, dim=0)\n",
    "        return mean_latent, var_latent\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def generate_eeg_from_word(model, word, train_dataloder, num_samples=5):\n",
    "    \"\"\"\n",
    "    Generate new EEG features for a given word\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    mean_latent, var_latent = get_latent_by_word(model, train_dataloder, word)\n",
    "    \n",
    "    if mean_latent is None:\n",
    "        print(f\"No samples found for word: {word}\")\n",
    "        return None\n",
    "    \n",
    "    generated_samples = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            eps = torch.randn_like(var_latent)\n",
    "            z = mean_latent + eps * torch.sqrt(var_latent)\n",
    "            \n",
    "            generated = model.decode(z.unsqueeze(0))\n",
    "            generated_samples.append(generated)\n",
    "    \n",
    "    return torch.cat(generated_samples, dim=0)\n",
    "\n",
    "def analyze_generated_samples(model, word, train_dataloder, num_samples=5):\n",
    "    \"\"\"\n",
    "    Generate a number of eeg data samples for a word and returns both original and new\n",
    "    \"\"\"\n",
    "    real_samples = []\n",
    "    real_found = False\n",
    "    \n",
    "    for batch in train_dataloder:\n",
    "        labels = batch['label']\n",
    "        eeg_feats = batch['eeg_raw']\n",
    "        \n",
    "        \n",
    "        word_indices = [i for i, label in enumerate(labels) if label == word]\n",
    "        if word_indices:\n",
    "            real_found = True\n",
    "            real_samples.append(eeg_feats[word_indices])\n",
    "    \n",
    "    if not real_found:\n",
    "        print(f\"No real samples found for word: {word}\")\n",
    "        return\n",
    "    \n",
    "    real_samples = torch.cat(real_samples, dim=0)\n",
    "    \n",
    "    generated_samples = generate_eeg_from_word(model, word, train_dataloder, num_samples)\n",
    "    \n",
    "    if generated_samples is None:\n",
    "        return\n",
    "    \n",
    "    real_mean = torch.mean(real_samples, dim=0)\n",
    "    real_std = torch.std(real_samples, dim=0)\n",
    "    gen_mean = torch.mean(generated_samples, dim=0)\n",
    "    gen_std = torch.std(generated_samples, dim=0)\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    print(f\"Real mean range: [{torch.min(real_mean):.3f}, {torch.max(real_mean):.3f}]\")\n",
    "    print(f\"Generated mean range: [{torch.min(gen_mean):.3f}, {torch.max(gen_mean):.3f}]\")\n",
    "    print(f\"Real std range: [{torch.min(real_std):.3f}, {torch.max(real_std):.3f}]\")\n",
    "    print(f\"Generated std range: [{torch.min(gen_std):.3f}, {torch.max(gen_std):.3f}]\")\n",
    "    \n",
    "    return real_samples, generated_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_alice, generated_alice = analyze_generated_samples(model, 'Alice', train_dataloder, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eeg_comparison(real_samples, generated_samples, word):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(real_samples.shape[2]):\n",
    "        plt.plot(real_samples[0, :, i].cpu().numpy(), alpha=0.5)\n",
    "    plt.title(f'Real EEG for \"{word}\"')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i in range(generated_samples.shape[2]):\n",
    "        plt.plot(generated_samples[0, :, i].cpu().numpy(), alpha=0.5)\n",
    "    plt.title(f'Generated EEG for \"{word}\"')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_eeg_comparison(real_alice, generated_alice, 'Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_eeg_heatmaps(real_sample, generated_sample, word):\n",
    "   \"\"\"\n",
    "   Plot heatmap comparisons between real and generated EEG data\n",
    "   \"\"\"\n",
    "   fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "   \n",
    "   sns.heatmap(real_sample.cpu().numpy().T, \n",
    "               ax=ax1, \n",
    "               cmap='viridis',\n",
    "               cbar_kws={'label': 'Amplitude'})\n",
    "   ax1.set_title(f'Real EEG Pattern for \"{word}\"')\n",
    "   ax1.set_xlabel('Time')\n",
    "   ax1.set_ylabel('Features')\n",
    "   \n",
    "   sns.heatmap(generated_sample.cpu().numpy().T, \n",
    "               ax=ax2, \n",
    "               cmap='viridis',\n",
    "               cbar_kws={'label': 'Amplitude'})\n",
    "   ax2.set_title(f'Generated EEG Pattern for \"{word}\"')\n",
    "   ax2.set_xlabel('Time')\n",
    "   ax2.set_ylabel('Features')\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eeg_heatmaps(real_alice[0], generated_alice[0], 'Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_latent_dict(model, train_dataloder):\n",
    "    \"\"\" Returns dict of label:latent \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    word_latents_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(train_dataloder):\n",
    "            labels = batch['label']\n",
    "            eeg_feats = batch['eeg_raw'].float().to(device)\n",
    "            \n",
    "            for i, label in enumerate(labels):\n",
    "                if label not in word_latents_dict:\n",
    "                    word_latents_dict[label] = []\n",
    "                \n",
    "                eeg_sample = eeg_feats[i]\n",
    "                mu, _ = model.encode(eeg_sample.unsqueeze(0))\n",
    "                word_latents_dict[label].append(mu)\n",
    "                \n",
    "            \n",
    "                \n",
    "    for key in word_latents_dict:\n",
    "        word_latents_dict[key] = torch.cat(word_latents_dict[key], dim=0)\n",
    "        \n",
    "    return word_latents_dict\n",
    "\n",
    "def mean_std_latent_dict(word_latents_dict):\n",
    "    ''' calculates mean and std for each word in word_latents_dict '''\n",
    "    mean_latent_dict = {}\n",
    "    std_latent_dict = {}\n",
    "    \n",
    "    for key in word_latents_dict:\n",
    "        mean_latent_dict[key] = torch.mean(word_latents_dict[key], dim=0)\n",
    "        std_latent_dict[key] = torch.std(word_latents_dict[key], dim=0)\n",
    "        \n",
    "    return mean_latent_dict, std_latent_dict\n",
    "\n",
    "def word_augmentation_dict(mean_latent_dict, std_latent_dict, num_samples=100):\n",
    "    \"\"\" Creates dict with word:generated_samples (shape #generated x time x features) \"\"\"\n",
    "    word_augmentation_dict = {}\n",
    "    \n",
    "    for key in mean_latent_dict:\n",
    "        word_augmentation_dict[key] = []\n",
    "        for i in range(num_samples):\n",
    "            eps = torch.randn_like(std_latent_dict[key])\n",
    "            z = mean_latent_dict[key] + eps * torch.sqrt(std_latent_dict[key])\n",
    "            generated = model.decode(z.unsqueeze(0))\n",
    "            word_augmentation_dict[key].append(generated)\n",
    "            \n",
    "        word_augmentation_dict[key] = torch.cat(word_augmentation_dict[key], dim=0)\n",
    "    \n",
    "    return word_augmentation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = word_latent_dict(model, train_dataloder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avaraged_dict, test_std_dict = mean_std_latent_dict(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/ocean/projects/cis240129p/soederha/silent_speech/raw_model2_mean.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump(test_avaraged_dict, pickle_file)\n",
    "with open(\"/ocean/projects/cis240129p/soederha/silent_speech/raw_model2_std.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump(test_std_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_augmentation_dict(mean_latent_dict, std_latent_dict, num_samples, batch_size=1):\n",
    "    word_augmentation_dict = {}\n",
    "    \n",
    "    for key in mean_latent_dict.keys():\n",
    "        word_augmentation_dict[key] = []\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            current_batch_size = min(batch_size, num_samples - i)\n",
    "            eps = torch.randn(current_batch_size, *std_latent_dict[key].shape, device=std_latent_dict[key].device)\n",
    "            z = mean_latent_dict[key].unsqueeze(0) + eps * torch.sqrt(std_latent_dict[key].unsqueeze(0))\n",
    "            generated = model.decode(z)\n",
    "            word_augmentation_dict[key].append(generated)\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        word_augmentation_dict[key] = torch.cat(word_augmentation_dict[key], dim=0)\n",
    "    \n",
    "    return word_augmentation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_augmentation_dict = word_augmentation_dict(test_avaraged_dict, test_std_dict, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_augmentation_dict['you'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_chapter = pd.read_csv('/ocean/projects/cis240129p/shared/data/eeg_alice/AliceChapterOne-EEG.csv').iloc[:,0]\n",
    "new_subject = np.empty((520*len(alice_chapter), 60))\n",
    "for i in range(len(alice_chapter)):\n",
    "    word = alice_chapter[i]\n",
    "    if word not in test_augmentation_dict:\n",
    "        print(f\"Word '{word}' not found in augmentation dict\")\n",
    "    else:\n",
    "        random_coice = 0\n",
    "        new_subject[i*159:(i+1)*159] = test_augmentation_dict[word][random_coice].cpu().detach().numpy()\n",
    "        \n",
    "print(new_subject.shape)\n",
    "print(new_subject)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create .npy file from the new subject\n",
    "#np.save('/ocean/projects/cis240129p/soederha/newsubject_eegfeats_final_epoch40.npy', new_subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
