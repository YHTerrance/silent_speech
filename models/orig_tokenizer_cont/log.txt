['20241127recognition_model.py', '--output_directory', './models/orig_tokenizer_cont/', '--epochs', '100', '--batch_size', '4', '--start_training_from', 'models/orig_tokenizer/model.pt']
train / dev / test split: 638 143 143
max sequence length: 9539
finished epoch 1 - training loss: 2.5443 training WER:95.98 validation WER: 95.56 lr: 0.0003
finished epoch 2 - training loss: 2.4343 training WER:95.65 validation WER: 95.00 lr: 4.7999999999999994e-05
finished epoch 3 - training loss: 2.3858 training WER:95.39 validation WER: 96.92 lr: 4.7999999999999994e-05
finished epoch 4 - training loss: 2.4042 training WER:95.74 validation WER: 95.81 lr: 4.7999999999999994e-05
finished epoch 5 - training loss: 2.4714 training WER:95.65 validation WER: 95.13 lr: 4.7999999999999994e-05
finished epoch 6 - training loss: 2.4505 training WER:95.58 validation WER: 97.22 lr: 4.7999999999999994e-05
finished epoch 7 - training loss: 2.3355 training WER:95.12 validation WER: 95.56 lr: 4.7999999999999994e-05
finished epoch 8 - training loss: 2.1662 training WER:94.01 validation WER: 96.72 lr: 4.7999999999999994e-05
finished epoch 9 - training loss: 2.0250 training WER:92.66 validation WER: 96.41 lr: 4.7999999999999994e-05
finished epoch 10 - training loss: 1.8990 training WER:91.14 validation WER: 94.49 lr: 4.7999999999999994e-05
finished epoch 11 - training loss: 1.7992 training WER:89.68 validation WER: 94.42 lr: 4.7999999999999994e-05
finished epoch 12 - training loss: 1.6903 training WER:88.10 validation WER: 94.42 lr: 4.7999999999999994e-05
finished epoch 13 - training loss: 1.5840 training WER:85.42 validation WER: 95.03 lr: 4.7999999999999994e-05
finished epoch 14 - training loss: 1.5000 training WER:83.32 validation WER: 96.99 lr: 4.7999999999999994e-05
finished epoch 15 - training loss: 1.4225 training WER:81.27 validation WER: 96.41 lr: 4.7999999999999994e-05
finished epoch 16 - training loss: 1.2937 training WER:78.92 validation WER: 95.66 lr: 4.7999999999999994e-05
finished epoch 17 - training loss: 1.2240 training WER:76.00 validation WER: 94.97 lr: 4.7999999999999994e-05
finished epoch 18 - training loss: 1.1123 training WER:72.44 validation WER: 95.86 lr: 4.7999999999999994e-05
finished epoch 19 - training loss: 1.0013 training WER:69.05 validation WER: 95.86 lr: 4.7999999999999994e-05
finished epoch 20 - training loss: 0.9312 training WER:65.94 validation WER: 95.78 lr: 4.7999999999999994e-05
finished epoch 21 - training loss: 0.8832 training WER:64.05 validation WER: 96.49 lr: 4.7999999999999994e-05
finished epoch 22 - training loss: 0.8597 training WER:61.98 validation WER: 95.33 lr: 4.7999999999999994e-05
finished epoch 23 - training loss: 0.8103 training WER:61.22 validation WER: 95.33 lr: 4.7999999999999994e-05
finished epoch 24 - training loss: 0.7594 training WER:58.92 validation WER: 95.78 lr: 4.7999999999999994e-05
finished epoch 25 - training loss: 0.7063 training WER:56.88 validation WER: 95.76 lr: 4.7999999999999994e-05
finished epoch 26 - training loss: 0.6706 training WER:55.23 validation WER: 95.73 lr: 4.7999999999999994e-05
finished epoch 27 - training loss: 0.6504 training WER:53.79 validation WER: 96.34 lr: 4.7999999999999994e-05
finished epoch 28 - training loss: 0.6423 training WER:53.02 validation WER: 95.68 lr: 4.7999999999999994e-05
finished epoch 29 - training loss: 0.6135 training WER:52.20 validation WER: 95.48 lr: 4.7999999999999994e-05
finished epoch 30 - training loss: 0.5649 training WER:49.42 validation WER: 96.16 lr: 4.7999999999999994e-05
finished epoch 31 - training loss: 0.5036 training WER:46.01 validation WER: 96.24 lr: 4.7999999999999994e-05
finished epoch 32 - training loss: 0.4459 training WER:42.39 validation WER: 96.69 lr: 4.7999999999999994e-05
finished epoch 33 - training loss: 0.3861 training WER:37.72 validation WER: 96.57 lr: 4.7999999999999994e-05
finished epoch 34 - training loss: 0.3325 training WER:33.85 validation WER: 95.48 lr: 4.7999999999999994e-05
finished epoch 35 - training loss: 0.2733 training WER:29.45 validation WER: 95.30 lr: 4.7999999999999994e-05
finished epoch 36 - training loss: 0.2478 training WER:26.94 validation WER: 94.90 lr: 4.7999999999999994e-05
finished epoch 37 - training loss: 0.2336 training WER:25.44 validation WER: 94.47 lr: 4.7999999999999994e-05
finished epoch 38 - training loss: 0.2188 training WER:24.20 validation WER: 94.47 lr: 4.7999999999999994e-05
finished epoch 39 - training loss: 0.1969 training WER:21.59 validation WER: 94.80 lr: 4.7999999999999994e-05
finished epoch 40 - training loss: 0.1742 training WER:20.24 validation WER: 94.47 lr: 4.7999999999999994e-05
finished epoch 41 - training loss: 0.1524 training WER:19.01 validation WER: 94.55 lr: 4.7999999999999994e-05
finished epoch 42 - training loss: 0.1314 training WER:16.85 validation WER: 94.60 lr: 4.7999999999999994e-05
finished epoch 43 - training loss: 0.1119 training WER:15.36 validation WER: 94.70 lr: 4.7999999999999994e-05
finished epoch 44 - training loss: 0.1011 training WER:14.72 validation WER: 94.75 lr: 4.7999999999999994e-05
finished epoch 45 - training loss: 0.0947 training WER:13.47 validation WER: 95.08 lr: 4.7999999999999994e-05
finished epoch 46 - training loss: 0.0876 training WER:12.86 validation WER: 95.83 lr: 4.7999999999999994e-05
finished epoch 47 - training loss: 0.0836 training WER:12.28 validation WER: 95.53 lr: 4.7999999999999994e-05
finished epoch 48 - training loss: 0.0779 training WER:11.94 validation WER: 95.33 lr: 4.7999999999999994e-05
finished epoch 49 - training loss: 0.0687 training WER:10.57 validation WER: 95.38 lr: 4.7999999999999994e-05
finished epoch 50 - training loss: 0.0598 training WER:10.10 validation WER: 95.81 lr: 4.7999999999999994e-05
finished epoch 51 - training loss: 0.0561 training WER:10.25 validation WER: 95.71 lr: 4.7999999999999994e-05
finished epoch 52 - training loss: 0.0491 training WER:9.19 validation WER: 95.45 lr: 4.7999999999999994e-05
finished epoch 53 - training loss: 0.0442 training WER:8.51 validation WER: 95.05 lr: 4.7999999999999994e-05
finished epoch 54 - training loss: 0.0419 training WER:8.05 validation WER: 95.15 lr: 4.7999999999999994e-05
finished epoch 55 - training loss: 0.0389 training WER:8.09 validation WER: 95.15 lr: 4.7999999999999994e-05
finished epoch 56 - training loss: 0.0329 training WER:7.28 validation WER: 95.20 lr: 4.7999999999999994e-05
finished epoch 57 - training loss: 0.0270 training WER:6.89 validation WER: 95.43 lr: 4.7999999999999994e-05
finished epoch 58 - training loss: 0.0239 training WER:6.46 validation WER: 95.61 lr: 4.7999999999999994e-05
finished epoch 59 - training loss: 0.0208 training WER:6.50 validation WER: 95.40 lr: 4.7999999999999994e-05
finished epoch 60 - training loss: 0.0177 training WER:6.03 validation WER: 95.08 lr: 4.7999999999999994e-05
finished epoch 61 - training loss: 0.0152 training WER:5.77 validation WER: 95.20 lr: 4.7999999999999994e-05
finished epoch 62 - training loss: 0.0140 training WER:5.69 validation WER: 95.05 lr: 4.7999999999999994e-05
finished epoch 63 - training loss: 0.0124 training WER:5.34 validation WER: 94.82 lr: 4.7999999999999994e-05
finished epoch 64 - training loss: 0.0116 training WER:5.33 validation WER: 94.95 lr: 4.7999999999999994e-05
finished epoch 65 - training loss: 0.0092 training WER:4.89 validation WER: 95.23 lr: 4.7999999999999994e-05
finished epoch 66 - training loss: 0.0084 training WER:4.96 validation WER: 94.72 lr: 4.7999999999999994e-05
finished epoch 67 - training loss: 0.0072 training WER:4.76 validation WER: 94.85 lr: 4.7999999999999994e-05
finished epoch 68 - training loss: 0.0075 training WER:4.91 validation WER: 95.03 lr: 4.7999999999999994e-05
finished epoch 69 - training loss: 0.0067 training WER:4.73 validation WER: 94.87 lr: 4.7999999999999994e-05
finished epoch 70 - training loss: 0.0064 training WER:4.70 validation WER: 95.05 lr: 4.7999999999999994e-05
finished epoch 71 - training loss: 0.0056 training WER:4.59 validation WER: 95.20 lr: 4.7999999999999994e-05
finished epoch 72 - training loss: 0.0053 training WER:4.47 validation WER: 95.15 lr: 4.7999999999999994e-05
finished epoch 73 - training loss: 0.0065 training WER:4.50 validation WER: 95.13 lr: 4.7999999999999994e-05
finished epoch 74 - training loss: 0.0095 training WER:4.65 validation WER: 95.48 lr: 4.7999999999999994e-05
finished epoch 75 - training loss: 0.0208 training WER:4.92 validation WER: 94.87 lr: 4.7999999999999994e-05
finished epoch 76 - training loss: 0.0849 training WER:7.69 validation WER: 95.20 lr: 4.7999999999999994e-05
finished epoch 77 - training loss: 0.1780 training WER:12.57 validation WER: 95.30 lr: 4.7999999999999994e-05
finished epoch 78 - training loss: 0.1124 training WER:9.75 validation WER: 94.97 lr: 4.7999999999999994e-05
finished epoch 79 - training loss: 0.0577 training WER:7.16 validation WER: 94.72 lr: 4.7999999999999994e-05
finished epoch 80 - training loss: 0.0325 training WER:6.17 validation WER: 94.77 lr: 4.7999999999999994e-05
